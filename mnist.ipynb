{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data MNIST\n",
    "\n",
    "def get_images(img_file, number):\n",
    "    f = open(img_file, 'rb') # rb: open file in binary mode\n",
    "    f.read(16) # skip 16 bytes header\n",
    "    images = []\n",
    "\n",
    "    for i in range(number):\n",
    "        image = []\n",
    "        \n",
    "        for i in range(28*28):\n",
    "            image.append(ord(f.read(1))) # ord return the unicode for one-string character\n",
    "\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "def get_labels(label_file, number):\n",
    "    l = open(label_file, \"rb\") # similar above\n",
    "    l.read(8)\n",
    "    labels = []\n",
    "    for i in range(number):\n",
    "        labels.append(ord(l.read(1)))\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number in 2 functions get_images and get_labels is how many datas we'd like to get from file binary\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "from skimage import io # io: read and write image in various formats\n",
    "\n",
    "\n",
    "def convert_png(images, labels, directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)\n",
    "    \n",
    "    for i in range(len(images)):\n",
    "        out = os.path.join(directory,\"%06d-num%d.png\"%(i,labels[i]))\n",
    "        io.imsave(out, np.array(images[i]).reshape(28, 28))\n",
    "\n",
    "def output_csv(images, labels, out_file):\n",
    "    o = open(out_file, \"w\")\n",
    "    for i in range(len(images)):\n",
    "        o.write(\",\".join(str(x) for x in [labels[i]] + images[i]) + \"\\n\")\n",
    "    o.close()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n"
     ]
    }
   ],
   "source": [
    "print('Train')\n",
    "Training_size = 10000\n",
    "train_images = get_images('train-images-idx3-ubyte', Training_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Feature scaling\n",
    "\n",
    "## Viec chuan hoa du lieu 1 buoc quan trong \n",
    "## Vi data co the den tu nhieu nguon khac nhau nen co su chenh lech rat lon trong data\n",
    "\n",
    "train_images = np.array(train_images)/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = get_labels('train-labels-idx1-ubyte', Training_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haipro/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(C=100)\n",
    "clf.fit(train_images, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Test\n",
    "# load du lieu tu file test data va test voi model vua train\n",
    "TEST_SIZE = 500\n",
    "test_images = get_images('t10k-images-idx3-ubyte', TEST_SIZE)\n",
    "test_images = np.array(test_images)/255\n",
    "test_labels = get_labels('t10k-labels-idx1-ubyte', TEST_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict\n",
      "Result\n",
      "Score = 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        42\n",
      "           1       0.99      1.00      0.99        67\n",
      "           2       0.91      0.93      0.92        55\n",
      "           3       0.91      0.93      0.92        45\n",
      "           4       0.92      0.98      0.95        55\n",
      "           5       0.98      0.94      0.96        50\n",
      "           6       0.98      0.93      0.95        43\n",
      "           7       0.92      0.96      0.94        49\n",
      "           8       0.97      0.90      0.94        40\n",
      "           9       0.98      0.91      0.94        54\n",
      "\n",
      "   micro avg       0.95      0.95      0.95       500\n",
      "   macro avg       0.95      0.95      0.95       500\n",
      "weighted avg       0.95      0.95      0.95       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Predict')\n",
    "predict = clf.predict(test_images)\n",
    "\n",
    "print('Result')\n",
    "ac_score = metrics.accuracy_score(test_labels, predict)\n",
    "cl_report = metrics.classification_report(test_labels, predict)\n",
    "print('Score =', ac_score)\n",
    "print(cl_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The accuracy of model is 0.916, not bad. We hope improve this value by the way change the paramterer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameter_candidates = [\n",
    "    {'C': [0.001, 0.01, 0.1, 1, 5, 10, 100, 1000]}\n",
    "]\n",
    "\n",
    "clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
    "clf.fit(train_images, train_labels)\n",
    "print('Best score:', clf.best_score_)\n",
    "pritn('Best C:', clf.best_estimator_.C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
